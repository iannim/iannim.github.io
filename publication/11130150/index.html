<!DOCTYPE html><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.4.0 for Hugo" />
  

  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Michele Ianni" />

  
  
  
    
  
  <meta name="description" content="In this work, we present a novel approach for generating adversarial attacks on malware classification systems that rely on image-based representations of binary executables. Our method selectively applies obfuscation techniques to modify specific bytes in the binary, which correspond to adversarially perturbed pixels in the representation of malware as an image. By leveraging syntactic obfuscation strategies, we are able to transform the malware binary without compromising its functionality. Our results demonstrate that our approach effectively fools the CNN-based detection techniques, leading to misclassification. Additionally, we address the challenges associated with selective obfuscation, particularly when modified bytes map to noninstructional regions or structural elements of the binary. Overall, this research opens new avenues for understanding and defending against adversarial attacks in malware detection systems." />

  
  <link rel="alternate" hreflang="en-us" href="https://iannim.github.io/publication/11130150/" />

  
  
  
    <meta name="theme-color" content="#bbdefb" />
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.f1ecf783c14edc00c9320c205831ad8e.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'" disabled>
          <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'">
        
      
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.1b0e116046af73d16142214bba82f8a5.css" />

  



  


  


  




  
  
  

  

  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_huea36a7b1273dd89c88b17d4d756b6cd4_301670_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_huea36a7b1273dd89c88b17d4d756b6cd4_301670_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://iannim.github.io/publication/11130150/" />

  
  
  
  
  
  
  
  
    
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary" />
  
  <meta property="og:site_name" content="Michele Ianni" />
  <meta property="og:url" content="https://iannim.github.io/publication/11130150/" />
  <meta property="og:title" content="Evasion of Deep Learning Malware Detection via Adversarial Selective Obfuscation | Michele Ianni" />
  <meta property="og:description" content="In this work, we present a novel approach for generating adversarial attacks on malware classification systems that rely on image-based representations of binary executables. Our method selectively applies obfuscation techniques to modify specific bytes in the binary, which correspond to adversarially perturbed pixels in the representation of malware as an image. By leveraging syntactic obfuscation strategies, we are able to transform the malware binary without compromising its functionality. Our results demonstrate that our approach effectively fools the CNN-based detection techniques, leading to misclassification. Additionally, we address the challenges associated with selective obfuscation, particularly when modified bytes map to noninstructional regions or structural elements of the binary. Overall, this research opens new avenues for understanding and defending against adversarial attacks in malware detection systems." /><meta property="og:image" content="https://iannim.github.io/media/icon_huea36a7b1273dd89c88b17d4d756b6cd4_301670_512x512_fill_lanczos_center_3.png" />
    <meta property="twitter:image" content="https://iannim.github.io/media/icon_huea36a7b1273dd89c88b17d4d756b6cd4_301670_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2025-08-29T14:30:40&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2025-08-01T00:00:00&#43;00:00">
  

  


    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://iannim.github.io/publication/11130150/"
  },
  "headline": "Evasion of Deep Learning Malware Detection via Adversarial Selective Obfuscation",
  
  "datePublished": "2025-08-29T14:30:40Z",
  "dateModified": "2025-08-01T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Claudia Greco"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Michele Ianni",
    "logo": {
      "@type": "ImageObject",
      "url": "https://iannim.github.io/media/icon_huea36a7b1273dd89c88b17d4d756b6cd4_301670_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "In this work, we present a novel approach for generating adversarial attacks on malware classification systems that rely on image-based representations of binary executables. Our method selectively applies obfuscation techniques to modify specific bytes in the binary, which correspond to adversarially perturbed pixels in the representation of malware as an image. By leveraging syntactic obfuscation strategies, we are able to transform the malware binary without compromising its functionality. Our results demonstrate that our approach effectively fools the CNN-based detection techniques, leading to misclassification. Additionally, we address the challenges associated with selective obfuscation, particularly when modified bytes map to noninstructional regions or structural elements of the binary. Overall, this research opens new avenues for understanding and defending against adversarial attacks in malware detection systems."
}
</script>

  

  

  

  





  <title>Evasion of Deep Learning Malware Detection via Adversarial Selective Obfuscation | Michele Ianni</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper  dark " data-wc-page-id="c2daed6890df550182711578c3103461" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.6c07fd79b08c404df0504bd310968f2f.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#publications"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#contact"><span>Contact</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        

        
        
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    








<div class="pub">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Evasion of Deep Learning Malware Detection via Adversarial Selective Obfuscation</h1>

  

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Claudia Greco</span>, <span >
      Michele Ianni</span>, <span >
      Antonella Guzzo</span>, <span >
      Giancarlo Fortino</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    August, 2025
  </span>
  

  

  

  
  
  
  

  
  

</div>

    




<div class="btn-links mb-3">
  
  








  





<a href="#" class="btn btn-outline-primary btn-page-header js-cite-modal"
        data-filename="/publication/11130150/cite.bib">
  Cite
</a>













<a class="btn btn-outline-primary btn-page-header" href="https://doi.org/10.1109/CSR64739.2025.11130150" target="_blank" rel="noopener">
  DOI
</a>



</div>


  
</div>



  <div class="article-container">

    
    <h3>Abstract</h3>
    <p class="pub-abstract">In this work, we present a novel approach for generating adversarial attacks on malware classification systems that rely on image-based representations of binary executables. Our method selectively applies obfuscation techniques to modify specific bytes in the binary, which correspond to adversarially perturbed pixels in the representation of malware as an image. By leveraging syntactic obfuscation strategies, we are able to transform the malware binary without compromising its functionality. Our results demonstrate that our approach effectively fools the CNN-based detection techniques, leading to misclassification. Additionally, we address the challenges associated with selective obfuscation, particularly when modified bytes map to noninstructional regions or structural elements of the binary. Overall, this research opens new avenues for understanding and defending against adversarial attacks in malware detection systems.</p>
    

    
    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Type</div>
          <div class="col-12 col-md-9">
            <a href="/publication/#1">
              Conference paper
            </a>
          </div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Publication</div>
          <div class="col-12 col-md-9"><em>2025 IEEE International Conference on Cyber Security and Resilience (CSR)</em></div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    <div class="space-below"></div>

    <div class="article-style"></div>

    




<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/transforms/">Transforms</a>
  
  <a class="badge badge-light" href="/tag/syntactics/">Syntactics</a>
  
  <a class="badge badge-light" href="/tag/computer-crime/">Computer crime</a>
  
  <a class="badge badge-light" href="/tag/resilience/">Resilience</a>
  
  <a class="badge badge-light" href="/tag/malware/">Malware</a>
  
  <a class="badge badge-light" href="/tag/obfuscation/">Obfuscation</a>
  
  <a class="badge badge-light" href="/tag/adversarial-attacks/">Adversarial attacks</a>
  
  <a class="badge badge-light" href="/tag/deep-learning/">Deep learning</a>
  
  <a class="badge badge-light" href="/tag/binary-analysis/">Binary analysis</a>
  
</div>













  
  
    




  
    




  
    




  
    




  
















  </div>
</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  



  

  

  

  
  






  
  <p class="powered-by copyright-license-text">
    © 2025 Michele Ianni
  </p>
  




  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

      

    
    <script src="/js/vendor-bundle.min.3d946de2e8784a477845261d87025092.js"></script>

    
    
    
      
      
        <script src="https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js" integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw==" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js" integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin="anonymous"></script>
      

      
      

      

      
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js" integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin="anonymous"></script>
        
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/r.min.js" crossorigin="anonymous"></script>
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/latex.min.js" crossorigin="anonymous"></script>
        
      

    

    
    
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    
      
      
      
      
      
      
      
    

    

    
    
    
    <script id="page-data" type="application/json">{"use_headroom":true}</script>

    
    
      <script src="/js/wowchemy-headroom.e8fd2d733eef6a8bbbe0539398fc0547.js" type="module"></script>
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.a2ed145159dd33ad55ff402163350b5d.js"></script>

    
    
    
    
    
    
      
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      <script src="/js/wowchemy-publication.b0d291ed6d27eacec233e6cf5204f99a.js" type="module"></script>






</body>
</html>
