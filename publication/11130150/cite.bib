@inproceedings{11130150,
 abstract = {In this work, we present a novel approach for generating adversarial attacks on malware classification systems that rely on image-based representations of binary executables. Our method selectively applies obfuscation techniques to modify specific bytes in the binary, which correspond to adversarially perturbed pixels in the representation of malware as an image. By leveraging syntactic obfuscation strategies, we are able to transform the malware binary without compromising its functionality. Our results demonstrate that our approach effectively fools the CNN-based detection techniques, leading to misclassification. Additionally, we address the challenges associated with selective obfuscation, particularly when modified bytes map to noninstructional regions or structural elements of the binary. Overall, this research opens new avenues for understanding and defending against adversarial attacks in malware detection systems.},
 author = {Greco, Claudia and Ianni, Michele and Guzzo, Antonella and Fortino, Giancarlo},
 booktitle = {2025 IEEE International Conference on Cyber Security and Resilience (CSR)},
 doi = {10.1109/CSR64739.2025.11130150},
 issn = {},
 keywords = {Deep learning, Transforms, Syntactics, Malware, Computer crime, Resilience, malware, obfuscation, adversarial attacks, deep learning, binary analysis},
 month = {Aug},
 number = {},
 pages = {17-22},
 title = {Evasion of Deep Learning Malware Detection via Adversarial Selective Obfuscation},
 volume = {},
 year = {2025}
}
